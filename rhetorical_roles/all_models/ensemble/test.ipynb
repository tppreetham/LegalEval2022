{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from sklearn import preprocessing\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import sklearn.metrics\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "# import wordcloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/Rhetorical_Role_Benchmark/Data/train.json\"\n",
    "train_json = json.loads(urlopen(TRAIN_DATA).read())\n",
    "VAL_DATA = \"https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/Rhetorical_Role_Benchmark/Data/dev.json\"\n",
    "val_json = json.loads(urlopen(VAL_DATA).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_json(t_json):\n",
    "    docs = []\n",
    "    for rec in t_json:\n",
    "        doc = []\n",
    "        for line in rec['annotations'][0]['result']:\n",
    "            doc.append({'text': line['value']['text'], 'label': line['value']['labels'][0] \n",
    "            if len(line['value']['labels'])>0 else 'NONE'})\n",
    "        docs.append(doc)\n",
    "    docs_df = pd.json_normalize([item for sublist in docs for item in sublist])\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(docs_df.label)\n",
    "    sd = le.transform(docs_df.label)\n",
    "    docs_df.label = sd\n",
    "    return docs_df, docs\n",
    "# print(docs[9][0])\n",
    "t_docs_df, t_docs = preprocess_json(train_json)\n",
    "v_docs_df, v_docs = preprocess_json(val_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test): \n",
    "    print(len(y_pred), len(y_test))   \n",
    "    correct_pred = (y_pred == y_test)\n",
    "    print(correct_pred)\n",
    "    acc = correct_pred.sum() * 1.0 / len(correct_pred)\n",
    "    acc = np.round_(acc * 100, decimals = 3)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval = list(t_docs_df['text']), list(v_docs_df['text'])\n",
    "ytrain, yval = np.array(t_docs_df['label']), np.array(v_docs_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(xtrain+xval)\n",
    "xtrain_tfv = tfv.transform(xtrain) \n",
    "xval_tfv = tfv.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1.0, solver='liblinear', max_iter=1000)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xval_tfv)\n",
    "y_pred = [np.argmax(p) for p in predictions]\n",
    "# print(ytrain, y_pred)\n",
    "# print (\"logloss: %0.3f \" % multiclass_logloss(ytrain, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2879, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model_preds/tfidf_val_predss.pkl', 'wb')\n",
    "pickle.dump(predictions, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model_preds/deberta_val_preds.pkl', 'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27398/3993293784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
